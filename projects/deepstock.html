<div id="project_content">
<div class="title">DeepStock</div>
  <div class="details">2018 Â· Pytorch, DCGAN</div>
    <div class="subtitle">GAN-generated stock photos of salads.</div>
    <div class="description"><span class="bold">Astraea</span> was originally made for the class <a href="http://golancourses.net/2019/" class="text_link" target="_blank">Interactive Art</a>. The assignment was to make a tool for drawing, and I wanted to make something that would constrain what the artist was able to draw, but do so in a way that was meaningful rather than frustrating.</div><br>
    <div class="video_box"><iframe class="video" src="https://www.youtube.com/embed/Q4mplQBRrfM?rel=0" frameborder="0" allow="encrypted-media" allowfullscreen></iframe></div>
    <span class="description"><span class="bold">DeepStock</span>, also called ``Deep Pix2Stock Salad,'' was made as part of a group project for the course <a href="https://sites.google.com/site/artml2018/" class="text_link" target="_blank">Art and Machine Learning</a>. When we were first searching for a dataset, we struggled to find meaningful images that were not protected by copyright. This inspired us to use stock photos, famously royalty-free images which are available only because of the garish watermarks across them. In particular, we collected a dataset of 2134 images of salads from <a href="https://www.shutterstock.com/search?search_source=base_landing_page&language=en&searchterm=salad&image_type=all" class="text_link" target="_blank">Shutterstock</a>, since photos of salad are canonically generic. <br><br> My role in this project was to generate new stock photos, which I decided to do with my professor's <a href="https://github.com/bapoczos/ArtML/tree/master/DCGAN_Pytorch" class="text_link" target="_blank"> Pytorch representation of DCGAN</a>. I trained it on our dataset for 100 epochs (in initial trials, the model would start overfitting after about 105 epochs), and you can see a timelapse of its progress above. The images generated by this model looked good from a distance, but had very low resolution, so I decided to use <a href="https://phillipi.github.io/pix2pix/" class="text_link" target="_blank">Pix2Pix</a> to sharpen them and add texture. I trained a Pix2Pix model for 20 epochs where the A images were low-res versions of the pictures in our dataset, and their corresponding B images were the high-res versions. This model was surprisingly effective at improving image quality, and once the GAN-generated stock photos were passed through it, they had much more clearly defined bowls, leaves, and watermarks. Some examples of these final results are below.
    <br><br> I love the concept for this project, partially because the idea of generating more stock photos than there already are is so ridiculous, but also because it brings up interesting questions regarding creativity and ownership. Shutterstock owns all the images in my dataset, but who owns the images that the network has generated? Shutterstock? Me? The network? <span class="bold">DeepStock</span> encourages people to consider these important issues, but does so in a light-hearted and whimsical manner.<br><br></span>
    <div class="big image_box"><img src="data/projects/deep_stock1.png">A stock photo of a salad generated by DeepStock. I love the translucent bowl that still shows some of its contents. The gray bar at the bottom was a common feature across everything in the dataset.</div>
    <div class="big image_box"><img src="data/projects/deep_stock2.png">A stock photo of a salad generated by DeepStock. Though it isn't legible, there is still a very clear watermark across the image, and I love how the network learned to add that. Who is it trying to claim copyright for?</div>
    <div class="big image_box"><img src="data/projects/deep_stock3.png">Late training results from the Pix2Pix texturizer. The top row is the input images (low res), the second row is the ground truth (high res), and the third row is the pictures generated by the network; I think it did a great job adding detail to the images, and creating an impression of higher resolution (though the salads are still distorted).</div>
    <div class="big image_box"><img src="data/projects/deep_stock4.png">A demonstration of the effectiveness of the Pix2Pix texturizer: on the left is an image that was generated by the DCGAN network, and on the right is that same image after it was transformed by the Pix2Pix network. Shapes like lettuce leaves and shrimp bodies have sharpened, as have the hideous watermarks.</div>
</div>